### 目前能用的程序：
- 一个简单的shell脚本，可以定时调用scrapy_news.py维护数据库
- 一个简单的爬虫脚本（scrapy_news.py），里面只有两个方法，一个是初次爬取数据，一个是每天维护数据库数据的方法。现在爬的是六十多个文章栏目，视频栏目的爬虫还没写（逻辑是一样的，先实现其他部分）。
- 导出了一个文章的数据库，一共有一万七千多条文章，供需要的童鞋使用

### 剩下的工作：
- 这几天写好rest风格的后台接口。
- 再用python的GUI写一个桌面应用，这个桌面应用可以拿到每天最新的新闻数据，然后自动调用浏览器去执行（使用自动化测试框架实现），并且不会重复观看，除此之外就是一些搜索功能。
- 方案一：提供定时自动登录（selenium拿二维码+appium扫码）
- 方案二：分析api和js，构造请求函数，这样就可以用wxpy框架把这一套程序移植到微信公众号上了。（感觉提前去做这个会很干扰其他部分的进度，毕竟构造请求是个靠脑子和运气的事）

### 目前状态
- 桌面端程序api开发中
- **技术渣渣、龟速开发**

### 开发速度
- 边学边做，缓慢开发

